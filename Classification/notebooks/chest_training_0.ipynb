{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# New Section (Below is updated code from ChatGPT)"
      ],
      "metadata": {
        "id": "yNT5qie9Eq5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huRhGz6Yzqi6",
        "outputId": "207cb2e1-6411-4db0-8db8-e1a178ff2a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install medmnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXF896TuzvD8",
        "outputId": "91f2ac5d-e72b-4388-fe21-2d78a30f0ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting medmnist\n",
            "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.5.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.24.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.66.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (10.4.0)\n",
            "Collecting fire (from medmnist)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/87.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.20.0+cu121)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.4.2)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->medmnist) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (3.0.2)\n",
            "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=5db8d0430426bc6ee99dc224f608936cfd19749c9da3a2ae200cef991e4c48cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, medmnist\n",
            "Successfully installed fire-0.7.0 medmnist-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.models import resnet18\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "_7CbacFtzxDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "01wjnBv8z04F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define transformations for data augmentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize based on medical image domain\n",
        "])"
      ],
      "metadata": {
        "id": "puAh0xuPz2NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "class SingleLabelChestMNIST(Dataset):\n",
        "    def __init__(self, split, transform=None, size=224):\n",
        "        info = INFO['chestmnist']\n",
        "        DataClass = getattr(medmnist, info['python_class'])\n",
        "        self.data = DataClass(split=split, download=True, as_rgb=True, size=size)\n",
        "        self.imgs = self.data.imgs\n",
        "        self.labels = self.data.labels\n",
        "        self.transform = transform\n",
        "\n",
        "        # Filter out images that have more than one label\n",
        "        self.single_label_indices = [i for i in range(len(self.labels)) if self.labels[i].sum() == 1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.single_label_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.imgs[self.single_label_indices[idx]]\n",
        "        label = self.labels[self.single_label_indices[idx]].argmax()  # Convert one-hot to scalar label\n",
        "\n",
        "        # Convert NumPy array to PIL image\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label"
      ],
      "metadata": {
        "id": "CUa3wp4Mz31K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data with the specified size\n",
        "batch_size = 64\n",
        "train_dataset = SingleLabelChestMNIST(split='train', transform=transform, size=224)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = SingleLabelChestMNIST(split='test', transform=transform, size=224)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaznWuATz5sq",
        "outputId": "6f594259-27db-49a3-ae4a-52fad48907fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://zenodo.org/records/10519652/files/chestmnist_224.npz?download=1 to /root/.medmnist/chestmnist_224.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.89G/3.89G [00:41<00:00, 93.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/chestmnist_224.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Define the ResNet18 model\n",
        "class ChestMNISTModel(nn.Module):\n",
        "    def __init__(self, num_classes=14):\n",
        "        super(ChestMNISTModel, self).__init__()\n",
        "        self.model = resnet18(pretrained=True)\n",
        "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)  # Modify for single channel\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)  # Modify output for 14 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "EFn8aBrAz7Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChestMNISTModel(num_classes=14).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5d5H7ruz8t4",
        "outputId": "c74d7de8-7167-4543-9236-3d568b76335d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 117MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Training function\n",
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "lRYoDD6Xz_qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Validation function\n",
        "def validate(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, labels) in enumerate(test_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # For AUC calculation\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(outputs.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(test_loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "\n",
        "    # Calculate AUC\n",
        "    all_preds = torch.softmax(torch.tensor(all_preds), dim=1).numpy()\n",
        "    auc = roc_auc_score(all_labels, all_preds, multi_class='ovr')\n",
        "\n",
        "    return epoch_loss, epoch_acc, auc"
      ],
      "metadata": {
        "id": "eXPLFyCL0Ddt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Training loop with best model saving\n",
        "num_epochs = 100\n",
        "best_auc = 0.0  # Initialize best AUC score\n",
        "best_model_path = '/content/drive/MyDrive/best_model.pth'\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    # Train for one epoch\n",
        "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
        "    # Validate the model\n",
        "    val_loss, val_acc, val_auc = validate(model, test_loader, criterion, device)\n",
        "\n",
        "    # Print metrics for the current epoch\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%, Validation AUC: {val_auc:.4f}\")\n",
        "\n",
        "    # Update the scheduler based on validation AUC\n",
        "    scheduler.step(val_auc)\n",
        "\n",
        "    # Save model if AUC improves\n",
        "    if val_auc > best_auc:\n",
        "        best_auc = val_auc\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f\"New best model saved with AUC: {best_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t0YH6C8-0Mk-",
        "outputId": "e77fdd3b-77a2-4a54-9955-deb35ef5f6c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-1af0a9ab38d8>:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  all_preds = torch.softmax(torch.tensor(all_preds), dim=1).numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.1301, Train Accuracy: 31.68%\n",
            "Validation Loss: 2.1157, Validation Accuracy: 32.98%, Validation AUC: 0.6661\n",
            "New best model saved with AUC: 0.6661\n",
            "Epoch 2/100\n",
            "Train Loss: 2.0143, Train Accuracy: 35.19%\n",
            "Validation Loss: 2.1708, Validation Accuracy: 35.05%, Validation AUC: 0.6766\n",
            "New best model saved with AUC: 0.6766\n",
            "Epoch 3/100\n",
            "Train Loss: 1.9407, Train Accuracy: 37.48%\n",
            "Validation Loss: 2.0330, Validation Accuracy: 35.90%, Validation AUC: 0.7093\n",
            "New best model saved with AUC: 0.7093\n",
            "Epoch 4/100\n",
            "Train Loss: 1.8890, Train Accuracy: 39.10%\n",
            "Validation Loss: 1.9489, Validation Accuracy: 38.07%, Validation AUC: 0.7401\n",
            "New best model saved with AUC: 0.7401\n",
            "Epoch 5/100\n",
            "Train Loss: 1.8558, Train Accuracy: 40.26%\n",
            "Validation Loss: 1.9083, Validation Accuracy: 38.65%, Validation AUC: 0.7437\n",
            "New best model saved with AUC: 0.7437\n",
            "Epoch 6/100\n",
            "Train Loss: 1.8172, Train Accuracy: 41.49%\n",
            "Validation Loss: 1.8955, Validation Accuracy: 39.81%, Validation AUC: 0.7485\n",
            "New best model saved with AUC: 0.7485\n",
            "Epoch 7/100\n",
            "Train Loss: 1.7830, Train Accuracy: 42.64%\n",
            "Validation Loss: 1.8794, Validation Accuracy: 39.34%, Validation AUC: 0.7573\n",
            "New best model saved with AUC: 0.7573\n",
            "Epoch 8/100\n",
            "Train Loss: 1.7559, Train Accuracy: 43.06%\n",
            "Validation Loss: 1.8853, Validation Accuracy: 39.42%, Validation AUC: 0.7612\n",
            "New best model saved with AUC: 0.7612\n",
            "Epoch 9/100\n",
            "Train Loss: 1.7207, Train Accuracy: 44.04%\n",
            "Validation Loss: 1.8545, Validation Accuracy: 41.20%, Validation AUC: 0.7634\n",
            "New best model saved with AUC: 0.7634\n",
            "Epoch 10/100\n",
            "Train Loss: 1.6898, Train Accuracy: 45.01%\n",
            "Validation Loss: 1.8956, Validation Accuracy: 39.69%, Validation AUC: 0.7614\n",
            "Epoch 11/100\n",
            "Train Loss: 1.6541, Train Accuracy: 46.19%\n",
            "Validation Loss: 1.8956, Validation Accuracy: 39.83%, Validation AUC: 0.7672\n",
            "New best model saved with AUC: 0.7672\n",
            "Epoch 12/100\n",
            "Train Loss: 1.6210, Train Accuracy: 47.23%\n",
            "Validation Loss: 1.8638, Validation Accuracy: 40.79%, Validation AUC: 0.7726\n",
            "New best model saved with AUC: 0.7726\n",
            "Epoch 13/100\n",
            "Train Loss: 1.5867, Train Accuracy: 48.13%\n",
            "Validation Loss: 1.9186, Validation Accuracy: 40.04%, Validation AUC: 0.7595\n",
            "Epoch 14/100\n",
            "Train Loss: 1.5498, Train Accuracy: 49.02%\n",
            "Validation Loss: 1.8725, Validation Accuracy: 41.28%, Validation AUC: 0.7667\n",
            "Epoch 15/100\n",
            "Train Loss: 1.5069, Train Accuracy: 50.58%\n",
            "Validation Loss: 1.9121, Validation Accuracy: 40.02%, Validation AUC: 0.7645\n",
            "Epoch 16/100\n",
            "Train Loss: 1.4556, Train Accuracy: 51.92%\n",
            "Validation Loss: 1.9158, Validation Accuracy: 40.73%, Validation AUC: 0.7681\n",
            "Epoch 17/100\n",
            "Train Loss: 1.3940, Train Accuracy: 53.72%\n",
            "Validation Loss: 1.9633, Validation Accuracy: 41.08%, Validation AUC: 0.7657\n",
            "Epoch 18/100\n",
            "Train Loss: 1.3279, Train Accuracy: 55.93%\n",
            "Validation Loss: 1.9848, Validation Accuracy: 38.06%, Validation AUC: 0.7682\n",
            "Epoch 19/100\n",
            "Train Loss: 1.1293, Train Accuracy: 62.57%\n",
            "Validation Loss: 2.1786, Validation Accuracy: 38.89%, Validation AUC: 0.7552\n",
            "Epoch 20/100\n",
            "Train Loss: 0.9968, Train Accuracy: 66.92%\n",
            "Validation Loss: 2.2695, Validation Accuracy: 38.36%, Validation AUC: 0.7496\n",
            "Epoch 21/100\n",
            "Train Loss: 0.8881, Train Accuracy: 70.48%\n",
            "Validation Loss: 2.3977, Validation Accuracy: 38.20%, Validation AUC: 0.7505\n",
            "Epoch 22/100\n",
            "Train Loss: 0.7830, Train Accuracy: 74.29%\n",
            "Validation Loss: 2.6529, Validation Accuracy: 38.19%, Validation AUC: 0.7417\n",
            "Epoch 23/100\n",
            "Train Loss: 0.6913, Train Accuracy: 77.33%\n",
            "Validation Loss: 2.8580, Validation Accuracy: 36.83%, Validation AUC: 0.7345\n",
            "Epoch 24/100\n",
            "Train Loss: 0.6143, Train Accuracy: 79.62%\n",
            "Validation Loss: 2.9098, Validation Accuracy: 36.01%, Validation AUC: 0.7247\n",
            "Epoch 25/100\n",
            "Train Loss: 0.4417, Train Accuracy: 85.79%\n",
            "Validation Loss: 3.0553, Validation Accuracy: 37.05%, Validation AUC: 0.7317\n",
            "Epoch 26/100\n",
            "Train Loss: 0.3642, Train Accuracy: 88.43%\n",
            "Validation Loss: 3.0735, Validation Accuracy: 36.73%, Validation AUC: 0.7337\n",
            "Epoch 27/100\n",
            "Train Loss: 0.3238, Train Accuracy: 89.70%\n",
            "Validation Loss: 3.2671, Validation Accuracy: 36.68%, Validation AUC: 0.7256\n",
            "Epoch 28/100\n",
            "Train Loss: 0.2746, Train Accuracy: 91.05%\n",
            "Validation Loss: 3.4048, Validation Accuracy: 36.68%, Validation AUC: 0.7285\n",
            "Epoch 29/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8cb4c1800a70>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Validate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-688e2e7d76f8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}